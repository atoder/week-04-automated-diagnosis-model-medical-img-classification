{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ipython in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (7.8.0)\n",
      "Requirement already satisfied: jupyter in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (1.0.0)\n",
      "Requirement already satisfied: decorator in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from ipython) (4.4.0)\n",
      "Requirement already satisfied: prompt-toolkit<2.1.0,>=2.0.0 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from ipython) (2.0.9)\n",
      "Requirement already satisfied: pygments in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from ipython) (2.4.2)\n",
      "Requirement already satisfied: appnope; sys_platform == \"darwin\" in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from ipython) (0.1.0)\n",
      "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from ipython) (4.7.0)\n",
      "Requirement already satisfied: setuptools>=18.5 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from ipython) (41.2.0)\n",
      "Requirement already satisfied: backcall in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from ipython) (0.1.0)\n",
      "Requirement already satisfied: pickleshare in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from ipython) (0.7.5)\n",
      "Requirement already satisfied: traitlets>=4.2 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from ipython) (4.3.2)\n",
      "Requirement already satisfied: jedi>=0.10 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from ipython) (0.15.1)\n",
      "Requirement already satisfied: qtconsole in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from jupyter) (4.5.5)\n",
      "Requirement already satisfied: notebook in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from jupyter) (6.0.1)\n",
      "Requirement already satisfied: nbconvert in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from jupyter) (5.6.0)\n",
      "Requirement already satisfied: ipywidgets in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from jupyter) (7.5.1)\n",
      "Requirement already satisfied: ipykernel in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from jupyter) (5.1.2)\n",
      "Requirement already satisfied: jupyter-console in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from jupyter) (6.0.0)\n",
      "Requirement already satisfied: wcwidth in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython) (0.1.7)\n",
      "Requirement already satisfied: six>=1.9.0 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython) (1.12.0)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from pexpect; sys_platform != \"win32\"->ipython) (0.6.0)\n",
      "Requirement already satisfied: ipython-genutils in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from traitlets>=4.2->ipython) (0.2.0)\n",
      "Requirement already satisfied: parso>=0.5.0 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from jedi>=0.10->ipython) (0.5.1)\n",
      "Requirement already satisfied: jupyter-client>=4.1 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from qtconsole->jupyter) (5.3.3)\n",
      "Requirement already satisfied: jupyter-core in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from qtconsole->jupyter) (4.5.0)\n",
      "Requirement already satisfied: terminado>=0.8.1 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from notebook->jupyter) (0.8.2)\n",
      "Requirement already satisfied: Send2Trash in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from notebook->jupyter) (1.5.0)\n",
      "Requirement already satisfied: nbformat in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from notebook->jupyter) (4.4.0)\n",
      "Requirement already satisfied: pyzmq>=17 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from notebook->jupyter) (18.1.0)\n",
      "Requirement already satisfied: tornado>=5.0 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from notebook->jupyter) (6.0.3)\n",
      "Requirement already satisfied: jinja2 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from notebook->jupyter) (2.10.1)\n",
      "Requirement already satisfied: prometheus-client in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from notebook->jupyter) (0.7.1)\n",
      "Requirement already satisfied: defusedxml in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from nbconvert->jupyter) (0.6.0)\n",
      "Requirement already satisfied: mistune<2,>=0.8.1 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from nbconvert->jupyter) (0.8.4)\n",
      "Requirement already satisfied: bleach in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from nbconvert->jupyter) (3.1.0)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from nbconvert->jupyter) (1.4.2)\n",
      "Requirement already satisfied: entrypoints>=0.2.2 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from nbconvert->jupyter) (0.3)\n",
      "Requirement already satisfied: testpath in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from nbconvert->jupyter) (0.4.2)\n",
      "Requirement already satisfied: widgetsnbextension~=3.5.0 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from ipywidgets->jupyter) (3.5.1)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from jupyter-client>=4.1->qtconsole->jupyter) (2.8.0)\n",
      "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from nbformat->notebook->jupyter) (3.0.2)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from jinja2->notebook->jupyter) (1.1.1)\n",
      "Requirement already satisfied: webencodings in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from bleach->nbconvert->jupyter) (0.5.1)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat->notebook->jupyter) (19.1.0)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat->notebook->jupyter) (0.15.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install ipython jupyter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow-gpu\n",
    "!pip install h5py\n",
    "\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#download dataset\n",
    "!wget https://data.mendeley.com/datasets/rscbjbr9sj/2/files/41d542e7-7f91-47f6-9ff2-dd8e5a5a7861/ChestXRay2017.zip\n",
    "\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChestXRay2017.zip\r\n",
      "week-04-pneumonia-image-classification.ipynb\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Inspecting contents of ChestXRay2017.zip\n",
    "from zipfile import ZipFile\n",
    "\n",
    "with ZipFile(\"./ChestXRay2017.zip\", \"r\") as f:\n",
    "    f.extractall(path = \"./\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChestXRay2017.zip\r\n",
      "\u001b[1m\u001b[36m__MACOSX\u001b[m\u001b[m\r\n",
      "\u001b[1m\u001b[36mchest_xray\u001b[m\u001b[m\r\n",
      "week-04-pneumonia-image-classification.ipynb\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[36mtest\u001b[m\u001b[m  \u001b[1m\u001b[36mtrain\u001b[m\u001b[m\r\n"
     ]
    }
   ],
   "source": [
    "!ls chest_xray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[36mNORMAL\u001b[m\u001b[m    \u001b[1m\u001b[36mPNEUMONIA\u001b[m\u001b[m\r\n"
     ]
    }
   ],
   "source": [
    "!ls chest_xray/train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[36mNORMAL\u001b[m\u001b[m    \u001b[1m\u001b[36mPNEUMONIA\u001b[m\u001b[m\r\n"
     ]
    }
   ],
   "source": [
    "!ls chest_xray/test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating ImageGenerator instances for training, validating and testing\n",
    "from pathlib import Path\n",
    "\n",
    "train_files = \"./chest_xray/train/\"\n",
    "test_files = \"./chest_xray/test/\"\n",
    "\n",
    "positive_class_folder_name = \"PNEUMONIA\"\n",
    "negative_class_folder_name = \"NORMAL\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training-Pneumonia - 3883 \n",
      "Training-Normal - 1349 \n"
     ]
    }
   ],
   "source": [
    "# training files\n",
    "\n",
    "# number of X-RAYS which show Pneumonia\n",
    "P = Path(train_files + positive_class_folder_name + \"/\")\n",
    "temp = list(P.glob(\"*.jpeg\"))\n",
    "print(\"Training-Pneumonia - %i \" % len(temp))\n",
    "\n",
    "# number of X-RAYS which are normal\n",
    "P = P = Path(train_files + negative_class_folder_name + \"/\")\n",
    "temp = list(P.glob(\"*.jpeg\"))\n",
    "print(\"Training-Normal - %i \" % len(temp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing-Pneumonia - 390 \n",
      "Testing-Normal - 234 \n"
     ]
    }
   ],
   "source": [
    "# testing files\n",
    "\n",
    "# number of X-RAYS which show Pneumonia\n",
    "P = Path(test_files + positive_class_folder_name + \"/\")\n",
    "temp = list(P.glob(\"*.jpeg\"))\n",
    "print(\"Testing-Pneumonia - %i \" % len(temp))\n",
    "\n",
    "# number of X-RAYS which are normal\n",
    "P = P = Path(test_files + negative_class_folder_name + \"/\")\n",
    "temp = list(P.glob(\"*.jpeg\"))\n",
    "print(\"Testing-Normal - %i \" % len(temp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating ImageDataGenerators for training\n",
    "\n",
    "\"\"\"\n",
    "The training data generator must have other augmentation parameters in addition to the rescaling\n",
    "parameter `rescale`.\n",
    "\n",
    "Why?\n",
    "\n",
    "-   The model needs to trained to learn to focus on the essential pieces that determine the answer\n",
    "    inspite of the possible variations it may find in new X-RAY images. Augmentation parameters like\n",
    "    random zooming and flipping simulate unpredictable variations\n",
    "-   The test images should be just like the real-life examples of X-RAY images: they don't have the simulated\n",
    "    effects like those in the training data.\n",
    "-   The images used for validation during training must also be like the test-images.\n",
    "    \n",
    "\"\"\"\n",
    "\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_generator = ImageDataGenerator(featurewise_center = True,\n",
    "                                     shear_range = 0.2,\n",
    "                                     rescale = 1.0/255,\n",
    "                                     horizontal_flip = True,\n",
    "                                     validation_split = 0.2)\n",
    "\n",
    "test_generator = ImageDataGenerator(rescale = 1.0/255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4187 images belonging to 2 classes.\n",
      "Found 1045 images belonging to 2 classes.\n",
      "Found 624 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# create batch iterators for the train, validation and test data\n",
    "\n",
    "train_iterator = train_generator.flow_from_directory(train_files, \n",
    "                                                     target_size = (150, 150),\n",
    "                                                     classes = [positive_class_folder_name, negative_class_folder_name],\n",
    "                                                     batch_size = 256, \n",
    "                                                     shuffle = True, \n",
    "                                                     class_mode = \"binary\",\n",
    "                                                     subset = \"training\")\n",
    "                                                    \n",
    "validation_iterator = train_generator.flow_from_directory(train_files, \n",
    "                                                          target_size = (150, 150),\n",
    "                                                          classes = [positive_class_folder_name, negative_class_folder_name],\n",
    "                                                          batch_size = 128, \n",
    "                                                          shuffle = False, \n",
    "                                                          class_mode = \"binary\",\n",
    "                                                          subset = \"validation\")\n",
    "\n",
    "test_iterator = test_generator.flow_from_directory(test_files, \n",
    "                                                   target_size = (150, 150), \n",
    "                                                   classes = [positive_class_folder_name, negative_class_folder_name],\n",
    "                                                   batch_size = 64, \n",
    "                                                   shuffle = False,\n",
    "                                                   class_mode = \"binary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label 0 - 3107, Label 1 - 1080\n"
     ]
    }
   ],
   "source": [
    "# count for class instances in training data\n",
    "\n",
    "class1 = sum(train_iterator.classes)\n",
    "class0 = len(train_iterator.classes) - class1\n",
    "\n",
    "print(\"Label 0 - %i, Label 1 - %i\" % (class0, class1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label 0 - 776, Label 1 - 269\n"
     ]
    }
   ],
   "source": [
    "# count for class instances in validation data\n",
    "\n",
    "class1 = sum(validation_iterator.classes)\n",
    "class0 = len(validation_iterator.classes) - class1\n",
    "\n",
    "print(\"Label 0 - %i, Label 1 - %i\" % (class0, class1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label 0 - 390, Label 1 - 234\n"
     ]
    }
   ],
   "source": [
    "# count for class instances in testing data\n",
    "\n",
    "class1 = sum(test_iterator.classes)\n",
    "class0 = len(test_iterator.classes) - class1\n",
    "\n",
    "print(\"Label 0 - %i, Label 1 - %i\" % (class0, class1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.67380109, 1.93842593])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#As per as the output of the previous 3 cells, we can deduce that ImageGenerator assigns the numeric labels as:\n",
    "#negative_class_folder_name -> the label 1\n",
    "#positive_class_folder_name -> the label 0\n",
    "# defining category label weights as per imbalance amount of the training dataset\n",
    "\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "y = train_iterator.classes\n",
    "labels = np.unique(y)\n",
    "\n",
    "train_class_weights = compute_class_weight(\"balanced\", labels, y)\n",
    "train_class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 5681680000031690511\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "# Transfer Learning using the InceptionV3 pretrained CNN\n",
    "# are the Colab GPUs available to tensorflow?\n",
    "\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.backend import clear_session\n",
    "\n",
    "from tensorflow.keras.layers import Dropout, GlobalAveragePooling2D, BatchNormalization, Dense\n",
    "\n",
    "from tensorflow.keras.models import Sequential, load_model, save_model\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "from tensorflow.keras.optimizers import RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0928 21:17:07.391397 4619916736 deprecation.py:323] From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inception_v3 (Model)         (None, 3, 3, 2048)        21802784  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1024)              2098176   \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 24,590,113\n",
      "Trainable params: 2,787,329\n",
      "Non-trainable params: 21,802,784\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Modify the Inception V3 CNN as per as the output requirements\n",
    "clear_session()\n",
    "\n",
    "base_model = InceptionV3(weights = \"imagenet\", include_top = False, input_shape = (150, 150, 3))\n",
    "clear_output()\n",
    "\n",
    "base_model.trainable = False\n",
    "myModel = Sequential([base_model,\n",
    "                      GlobalAveragePooling2D(),\n",
    "                      Dense(1024, activation = \"relu\"),\n",
    "                      Dropout(0.3),\n",
    "                      Dense(512, activation = \"relu\"),\n",
    "                      Dropout(0.3),\n",
    "                      Dense(256, activation = \"relu\"),\n",
    "                      Dropout(0.3),\n",
    "                      Dense(128, activation = \"relu\"),\n",
    "                      Dropout(0.3),\n",
    "                      Dense(1, activation = \"sigmoid\")])\n",
    "\n",
    "myModel.compile(RMSprop(), loss = \"binary_crossentropy\", metrics = [\"accuracy\"])\n",
    "myModel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "17/17 [==============================] - 314s 18s/step - loss: 0.2112 - acc: 0.9157 - val_loss: 1.0538 - val_acc: 0.7675\n",
      "Epoch 2/10\n",
      "17/17 [==============================] - 393s 23s/step - loss: 0.2265 - acc: 0.9126 - val_loss: 0.4659 - val_acc: 0.8498\n",
      "Epoch 3/10\n",
      "17/17 [==============================] - 320s 19s/step - loss: 0.2010 - acc: 0.9236 - val_loss: 1.3676 - val_acc: 0.5818\n",
      "Epoch 4/10\n",
      "17/17 [==============================] - 320s 19s/step - loss: 0.2197 - acc: 0.9123 - val_loss: 1.0014 - val_acc: 0.7694\n",
      "Epoch 5/10\n",
      "17/17 [==============================] - 370s 22s/step - loss: 0.1984 - acc: 0.9200 - val_loss: 0.3314 - val_acc: 0.8574\n",
      "Epoch 6/10\n",
      "17/17 [==============================] - 400s 24s/step - loss: 0.2065 - acc: 0.9159 - val_loss: 0.2914 - val_acc: 0.8632\n",
      "Epoch 7/10\n",
      "17/17 [==============================] - 293s 17s/step - loss: 0.1873 - acc: 0.9219 - val_loss: 0.3177 - val_acc: 0.8727\n",
      "Epoch 8/10\n",
      "17/17 [==============================] - 315s 19s/step - loss: 0.1911 - acc: 0.9243 - val_loss: 0.4981 - val_acc: 0.7656\n",
      "Epoch 9/10\n",
      "17/17 [==============================] - 206s 12s/step - loss: 0.1887 - acc: 0.9288 - val_loss: 0.4631 - val_acc: 0.8096\n",
      "Epoch 10/10\n",
      "17/17 [==============================] - 210s 12s/step - loss: 0.1873 - acc: 0.9274 - val_loss: 0.5402 - val_acc: 0.7990\n"
     ]
    }
   ],
   "source": [
    "#Train the model\n",
    "history = myModel.fit_generator(train_iterator, \n",
    "                                steps_per_epoch = len(train_iterator),\n",
    "                                epochs = 10,\n",
    "                                verbose = 1,\n",
    "                                workers = 20,\n",
    "                                validation_data = validation_iterator, \n",
    "                                validation_steps = len(validation_iterator),\n",
    "                                class_weight = train_class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the model\n",
    "save_model(myModel, \"./myModel_after_10_epochs\", overwrite = True, include_optimizer = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load myModel from local directory if required\n",
    "myModel = load_model(\"./myModel_after_10_epochs\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   PNEUMONIA       0.64      1.00      0.78       390\n",
      "      NORMAL       0.92      0.05      0.09       234\n",
      "\n",
      "    accuracy                           0.64       624\n",
      "   macro avg       0.78      0.52      0.43       624\n",
      "weighted avg       0.74      0.64      0.52       624\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Compute Evalution Metrics\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "yhat = myModel.predict_generator(test_iterator,\n",
    "                                 steps = len(test_iterator),\n",
    "                                 verbose = 0)  \n",
    "mask = yhat > 0.5\n",
    "yhat[mask] = 1\n",
    "yhat[~mask] = 0\n",
    "\n",
    "y = test_iterator.classes\n",
    "\n",
    "target_names = [positive_class_folder_name, negative_class_folder_name]\n",
    "print(classification_report(y, yhat, target_names = target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   PNEUMONIA       0.64      1.00      0.78       390\n",
      "      NORMAL       0.92      0.05      0.09       234\n",
      "\n",
      "    accuracy                           0.64       624\n",
      "   macro avg       0.78      0.52      0.43       624\n",
      "weighted avg       0.74      0.64      0.52       624\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Compute Evaluation Metrics\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "yhat = myModel.predict_generator(test_iterator,\n",
    "                                 steps = len(test_iterator),\n",
    "                                 verbose = 0)  \n",
    "mask = yhat > 0.5\n",
    "yhat[mask] = 1\n",
    "yhat[~mask] = 0\n",
    "\n",
    "y = test_iterator.classes\n",
    "\n",
    "target_names = [positive_class_folder_name, negative_class_folder_name]\n",
    "print(classification_report(y, yhat, target_names = target_names))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (3.1.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from matplotlib) (2.4.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from matplotlib) (1.1.0)\n",
      "Requirement already satisfied: numpy>=1.11 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from matplotlib) (1.17.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from matplotlib) (0.10.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from matplotlib) (2.8.0)\n",
      "Requirement already satisfied: setuptools in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from kiwisolver>=1.0.1->matplotlib) (41.2.0)\n",
      "Requirement already satisfied: six in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from cycler>=0.10->matplotlib) (1.12.0)\n",
      "Collecting cv2\n",
      "\u001b[31m  ERROR: Could not find a version that satisfies the requirement cv2 (from versions: none)\u001b[0m\n",
      "\u001b[31mERROR: No matching distribution found for cv2\u001b[0m\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'cv2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-54-bc6028fdbade>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mfile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_files\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtest_file_names\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIMREAD_COLOR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m     \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2RGB\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cv2' is not defined"
     ]
    }
   ],
   "source": [
    "#test output\n",
    "!pip3 install matplotlib\n",
    "!pip3 install cv2\n",
    "from random import randint\n",
    "import matplotlib.pyplot as plt\n",
    "#import cv2\n",
    "\n",
    "from IPython import get_ipython\n",
    "%matplotlib inline\n",
    "\n",
    "label_dict = {0:\"PNEUMONIA\", 1:\"NORMAL\"}\n",
    "\n",
    "test_file_names = test_iterator.filenames\n",
    "n = len(test_file_names)\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = 12, 10\n",
    "\n",
    "for i in range(5):\n",
    "    index = randint(0, n - 1)\n",
    "    file_name = test_files + test_file_names[index]\n",
    "    \n",
    "    image = cv2.imread(file_name, cv2.IMREAD_COLOR)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    ground_truth_label = label_dict[int(y[index])]\n",
    "    predicted_label = label_dict[int(yhat[index])]\n",
    "    \n",
    "    plt.subplot(5, 1, i + 1)\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(image)\n",
    "    \n",
    "    title = \"Ground Truth = \" + ground_truth_label + \", Predicted Label = \" + predicted_label\n",
    "    plt.title(title)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
